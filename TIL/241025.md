# 241025 17일차 TIL

> #### 개인 실습 



**어제 진행했던 도전과제부분은 난이도 문제로 팀원분들이 진행하지**
**않기로했다. 모델만 만들어내면 끝나는 아쉬운상황이라**
**개인적으로 마무리까지 진행해보도록 할것이며,**
**오늘은 kaggle 데이터를 자유롭게 다운로드 받아서**
**특징과 레이블을 정해 머신러닝 모델을 만들어 볼것이다**

>##### 1 데이터셋 불러오기

```
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv('C:/Users/gemma/OneDrive/Desktop/sparta/database/all_perth_310121.csv')

print(df.info())
print(df.head())

```
대략적인 정보를 확인하기 위해 info와 head 함수를 사용했다. 

일단 주택에 관련된 정보인것을 확인할수있고, 침실수,화장실수,차고차량수,토지면적,건축연도를 통해서 가격을 한번 예측해보려고한다.

결측치는 garage에 약 2500개 가량 존재 하기에 주차를 할수 없다고 가정을하고 결측치 처리를 값 0 으로 변경해 주려고한다.

건축연도 build_year 같은경우에도 결측치가 3000개 넘게 존재 하는걸 확인했고,

 결측치 값을 수정해주기 위해 describe로 전체 통계값을 확인해보았다.


`print(df.describe()) ` 

일단은 단순하게 시작을 했는데 통계값을 확인해보니, 이상치도 어느정도 존재하는것 같다. 토지면적이 999999로 찍혀 있거나 , 

주차차량가능수 같은경우도 99대가 최대값인걸 보니 이상치도 어느정도 처리를 해줘야 할거 같다. 

이후 이상치를 삭제해보려고 햇는데 문득 든 생각은 999999 나 99대의 주차댓수 이런식으로 데이터값을 냈다면

아마 주택가격부분도 저렇게 비슷한 이상치가 존재 할거라고 생각했고, 

그럼 이상치가 들어간 행을 전부다 일단 지워 보는건 어떨까? 라는 생각을 했다.

어차피 특징은 3만개가 넘어가니 무난히 학습을 시킬것으로 예상했다.

```
df['GARAGE']=df['GARAGE'].fillna(0)

print(df.isnull().sum())
```

이후 결측치를 확인해 보았는데 0으로 반환되었다.	

```
features =['BEDROOMS','BATHROOMS','GARAGE','LAND_AREA','BUILD_YEAR']
target = 'PRICE'
```

내가 알던건 변수에 값을 선언할때 df[['BEDROOMS,'BATHROOMS'~~'BUILD_YEAR']] 이렇게 입력을 해야 값이 선언이 되는걸로 알고있었는데,

어차피 features는 문자열의 리스트이기 때문에 pandas에서 각 항목의 열 이름으로 바로 인식 한다는걸 이번 실습을 통해 알게되었다.






###### IQR을 사용한 이상치 확인
```
def outlier(df, columns):
    for column in columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return df
```
내가 인터넷강의를 통해서 들은 IQR 방식에서의 가장 표준이 되는 코드라고 알고있다.

1사분위수(Q1) 계산 (25번째 백분위수) , 3사분위수(Q3) 계산 (75번째 백분위수) ,하한값,상한값에

대한 값  0.25,0.75,1.5는 가장 기본이 되는 값이다.

이후에 df에  상한값과 하한값 사이에 있는 값들만 필터링하여 남기고 나머지는 제거 해주었다.

```
df_clean = outlier(df, features + [target])

print(df_clean)
```
이후에 코드를 확인해보니 데이터가 33000개 가량이 14000개로 줄어들었다.
약 18000개 가량이 삭제된 셈인데 너무 데이터가 적은게 아닐까 싶은데 개인적으로 직접 자료를 찾아서
내가 직접 특징이나 가격까지 파악해서 실습하는 과정이라 자유롭기에 일단 진행해보기로 했다.

X = df_clean[features]
y = df_clean[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

내가 특정한 특징들의 값은 편차가 너무나 크다. 침실같은경우 최대값이 16이지만 토지 면적의 최대값은 999999이다.
그렇다는건 모델을 학습하고 예측을 했을때 침실의 수가 가격을 예측하는데 거의 의미가 부여되지 않지 않을까 싶어서 스케일링을 진행하였다.
```
model = LinearRegression()
model.fit(X_train_scaled, y_train)
```

`y_pred = model.predict(X_test_scaled)`

```
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared Score: {r2}")
```

r-squared score 값은 0.12 ... 12%?

MSE는 35301086098... 이건 뭐..

이게 내가 너무 많은 열을 삭제해서 학습이 제대로 되지 않은 걸까 ?

아니면 학습할때 필요한 특징이 너무 적었던게 문제 인걸까 ?

왜 이렇게 값이 낮게 나온지 궁금해서 gpt에게 물어봤고,

개선 방안을 알려줬는데 ,

1.이상치 처리 방법 개선

2.더많은 특성 추가

3.선형회귀 대신 비선형모델 사용

4.새로운 특성을 만들어서 추가

등을 개선방안으로 알려주었다.

자 그럼 일단 해결할수 있는 부분 부터 시작해보자. 첫번째는 이상치를 제거하는게 아니라 평균값으로 바꿔보자.

음? 근데 사실 의미가 있을까 싶은데 일단 진행.

이곳에서 진행하면 코드가 꼬여서 문제될까 걱정되서 다른 .py를 만들어 거기서 결측치를 평균값으로 변경해봤는데..

(이후 좀더 공부해본 결과 이상치의값은 평균값에 영향을 많이 줄수있으니까 ,

median 으로 중간값을 넣어줬어야된다는걸 깨달음 내일 좀더 수정하면서 진행 예정)

```
    column_mean = df_copy[column].mean()
        df_copy.loc[df_copy[column] < lower_bound, column] = column_mean
        df_copy.loc[df_copy[column] > upper_bound, column] = column_mean
```       
Mean Squared Error: 45740963892.314 , R-squared Score: 0.1501386267087671 예측률은 15% 정도로 상승했지만 MSE는 더 높이 치솟았다.

그래서 이번에는 다시 이상치를 제거하고 IQR값을 변경해보았다.

q1의 값을 0.2로 q3의 값을 0.8으로 계산 해봤고,

Mean Squared Error: 52182901863.88958 ,R-squared Score: 0.2030289455062677 예측률은 20프로 상승 MSE는 더 높아졌다. 

예측률이 올라갔으면 내 생각으로는 MSE도 당연히 0으로 가까워져야될텐데 왜 반비례할까 ? 궁금해졌다.

gpt를 통해 확인해 봤고 

R2 = 얼마나 잘 나타내는지 확인

MSE = 예측 값과 실제 값의 차이를 제곱해서 평균

즉 R2는 상대적인 성능을 나타내는거고 MSE는 절대적인 오차를 나타내기 때문에 다를수있다

그렇다면 R2는 모델에 많은 변수가 추가되면 올라갈수있고 , MSE는 이상치가 많으면 높아질수있으니까

이상치를 좀더 많이 제거해주면 왠지 치솟기만하는 MSE를 잡아낼수있을거같다.

Mean Squared Error: 21139569104.618073,R-squared Score: 0.06492206196231509 예측률은 0프로 지만 MSE는 60프로이상 줄이는데 성공했다.

의미가 있나... 여러가지 값들을 수정해 보았지만 만족할만한 값을 찾아내지 못했다.

내일 튜터님들한테 물어보고 마저 학습하자


-------------------------

**오늘의 회고**

오늘은 kaggle에서 데이터를 받아서
내 맘대로 자유롭게 학습하는 시간을 가졌다.
그런데 생각보다 평가가 너무 안좋아서... 맘이 안좋다..
gpt를 안쓰고 직접 코드를 생각하고 만들어 낸다는게 많이 어려운 작업인거 같다.
사실 오늘 대부분을 어제 도전과제를 완성하는데 사용했는데,
진척된 부분이 거의 없어서.. TIL 내용이 너무 적다.
아!! 그리고 기존에는 쥬피터를 사용하다가 오늘부터 vscode를 사용하기 시작했는데.
좋은점은 일단 화면이 어두워서 눈이 안 피로 하다.
나쁜점은 한줄 한줄 실행을 시키면서 결과를 확인했던 쥬피터를 쓰다가 
vscode를 쓰니 오류가 나면 어느부분에서 오류가 났는지 찾는데 시간을 쓰는게 불편하고,
실행을 시키면 반환 값이 터미널에서 나오다 보니까 가독성이 떨어진다고 그래야되나 ?
뭐.. 장단점이있는거니까.. 눈 안피곤 하면 됐지 뭐..
이번주도 고생 많았다! 다음주도 화이팅!

------------------------
