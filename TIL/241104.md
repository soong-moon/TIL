# 241104 22일차 TIL

> #### requirements.txt 개념 및 사용

프로젝트에서 사용된 모든 패키지와 그 버전을 기록해놓은 파일.
다른 개발자가 같은 환경을 구성할때 유용하다.

`pip freeze > requirements.txt`
파일 생성하는법이며, 생성하면 내가 만든 가상환경안의 패키지들과 버전이
txt 파일에 보여진다.

`pip install -r requirements.txt`
txt파일에있는 패키지를 해당 버전으로 설치.

내부적으로 빌드됐거나, 별도의 채널을 사용해서 경로를 명시한경우는
`pip install -r requirements.txt` 사용이 안될수있다.

별도로 콘다를 통해 패키지를 설치했는데 다른채널에서 설치한경우에는
conda에서 제공하는 requirements와 같은 개념을 사용하면 되는데,
방식은 다음과 같다.
`conda env export > {파일이름}.yml`
이걸 쓰면 아나콘다의 가상환경을 바로 생성할수잇꼬
`conda env create -f {파일이름}.yml`로 설치 진행가능하다.

일반적으로 아나콘다의 환경을 내보낼때는 `environment.yml`이며
pip의 패키지 목록은 `requirements.txt` 이다
해당 이름들은 관습처럼 사용되기에 알아두면 좋다.



> API란?
* 프로그램 간에 데이터를 주고 받을 수 있게 해주는 인터페이스이다.
쉽게 말해 , 서로 다른 소프트웨어가 대화 할수 있도록 돕는 일종의 통로라고 생각하면 된다.

* API는 서버와 클라이언트 간에 요청과 응답을 주고받는 방식으로 작동한다.
예를 들어, 앱에서 음성 인식을 원할때, 해당 API에 요청을 보내면 API가 그 요청을 처리하고 결과를 다시 보내주는 것.

***"Q. API 왜 중요한가?"***
API를 사용하면 복잡한 기능을 직접 구현할 필요 없이, 이미 만들어진 서비스를 활용할 수 있다.
특히 인공지능 API는 누구나 손쉽게 AI의 강력한 기능을 자신의 프로그램에 통합할 수 있게 해준다.


> ##### 인공지능 API의 활용 방법

1. 텍스트 생성 API:ChatGPT
ChatGPT는 OpenAI에서 제공하는 텍스트 생성 API이다.
이 API는 `GPT`라는 언어 모델을 기반으로, 사용자가 입력한 텍스트에 대해 자연스럽고 유창한 응답을 생성해 준다.
활용 예시 : 고객 응대 챗봇, 자동 문서 작성 도구, 교육 콘텐츠

2. 음성 합성 API: ElevenLabs
`ElevenLabs`는 자연스러운 음성을 생성해주는 AI 음성 합성 API.
이 API를 통해 텍스트를 인간의 목소리처럼 자연스럽게 읽어주는 기능을 사용할 수 있다.
활용 예시 : 오디오북 제작 , 팟캐스트 콘텐츠 생성 , 시각장애인을 위한 텍스트 읽기서비스

3. 컴퓨터 비전 API: Google Vision AI
이미지와 비디오 데이터를 분석해주는 API.
얼굴인식, 객체 탐지 , 텍스트 인식 등 다양한 비전 관련 작업을 수행 할수 있다.
활용 예시: 이미지 검색 기능, 보안카메라 분석 , 스마트 앨범

4. 음성 인식 API:Google Cloud Speech-to-text
음성을 텍스트로 변환해주는 서비스이다.
이 API는 다양한 언어를 지원하며, 실시간으로 음성을 텍스트로 변환할수 있다.
활용 예시:음성 기반 검색 엔진, 자동 회의록 생성, 음성 명령 처리

5. 번역 API :DeepL
`DeepL`은 고품질의 번역을 제공하는 서비스로, 자연스러운 번역 결과를 제공한다.
특히 기술 문서나 복잡한 텍스트를 번역하는 데 강점을 가진다.
활용 예시 : 글로벌 서비스의 다국어 지원, 번역 도구 ,국제 커뮤니케이션 지원


> ##### API 활용의 장단점

> 장점

1. 손쉬운 사용
복잡한 AI 기술을 직접 구현할 필요 없이, 간단한 API호출로 다양한 기능을 사용할수 있다.
2. 신속한 개발
빠르게 프로토타입을 만들고 , 새로운 기능을 통합 할수 있다.
3. 확장성
다양한 API를 결합해 복합적인 기능을 구현할수 있다.

> 단점

1. 비용
API사용에 따라 비용이 발생 할수 있으며, 특히 많은 양의 데이터를 처리할때 비용이 커질수 있다.
2. 제한된 제어
API는 제공된 기능만 사용할 수 있으며, 커스터마이징에는 제한이 있을수 있다.
3. 의존성
특성 API에 의존하게 되면, 해당 서비스가 중단되거나 변경 될때 문제가 발생 할수 있다.


>## PyTorch를 활용하여 Transformer 모델 구현하기

>PyTorch란 ?
딥러닝 프레임워크로, 유연하고 사용하기 쉬운 API 덕분에 연구자들과 개발자들 사이에서 많이 사용하는 프레임워크이다.
이 프레임 워크를 사용하면 딥러닝 모델을 쉽게 구축하고, 실험할수있다.

> Transformer 모델이란 ?
자연어 처리 (NLP)에서 뛰어난 성능을 보이는 모델이다.
Self-Attention 메커니즘을 활용해 텍스트의 문맥을 파악하고, 병렬처리에 강한 구조를 가지고 있다.
BERT,GPT,T5 같은 유명 모델들이 모두 Transformer 기반이다.

```
import torch
import torch.nn as nn
from torch.nn import Transformer

model = Transformer(d_model = 512 , nhead = 8 ,num_encoder_layers= 6 , num_decoder_layers= 6)
```
d_model은 단어의 인베딩 차원수를 나타낸다.
nhead는 multihead attention의 헤드수를 나타낸다.
encoder , decoder_layers 는 말 그대로 어느정도로 layer를 형성할지 나타낸다.

> ##### 사전 학습된 모델 활용하기

PyTorch 허브(Pytorch Hub)를 이용하면, 사전 학습된 다양한 모델들을 손쉽게 활용할 수 있다. 예를 들어, `torch.hub.load()`를 사용해 GPT-2 같은 사전 학습된 모델을 불러올 수 있다.

>##### 문제점

* 대형모델 학습에는 방대한 데이터를 필요로하고,학습에 많은 시간이 걸린다.
* 모델이 커질수록 메모리 사용량도 기하급수적으로 늘어난다.

* 복잡한 모델은 직접 만들기 힘들다.
Transformer 같은 모델은 구조가 복잡해서 처음부터 직접 구현하려면 많은 지식과 경험이 필요하다.
* 하이퍼파라미터 튜닝.
학습률,모델 크기,레이어 수등 다양한 하이퍼파라미터를 적절히 조절해야하는데, 이과정에서 시행착오가 많을수 있다.

* 사전 학습된 모델 활용의 한계
사전 학습된 모델은 특정 데이터나 작업에 대해 학습된 상태이기 때문에, 다른 작업에 맞추려면 추가적인 미세조정이 필요하다.
미세 조정이나 추가 학습을 하려면 대형 클라우드 서비스나 고성능 장비가 필요할수 있는데, 이는 상당한 비용을 요구한다.

> ##### 극복 방법

1. 클라우드 서비스 활용
Google Colab이나 AWS와 같은 클라우드 기반의 GPU 서비스를 활용하면, 개인 컴퓨터의 한계를 극복할수있다.
2. 사전 학습된 모델을 활용
Hugging Face의 `Transformers` 라이브러리나 `pytorch`Hub에서 제공하는 사전 학습된 모델을 활용하면,
복잡한 모델을 처음부터 구현하지 않아도 되며, 필요에 따라 일부 파라미터를 미세조정하여 자신만의 모델을 만들수있다.

3. 경령화 모델을 사용
`DistilBERT`나 `TinyBERT` 같은 경량화된 모델은 대형 모델의 성능을 유지하면서도 자원소모를 줄일수 있는 좋은 대안이 될수있다.

---------------------------------

오늘의 회고

아무리 무료로 부트캠프를 참여 하고 있지만 할말은 해야겠다.
강의 퀄리티 너무 떨어진다. 
강의를 통해서 얻는 부분은 정말 0에 가깝고 chatGPT나 구글링,유튜브, 타 유료강의를 통해 지식을 얻어야한다.
강의를 들으면서 뭔가 깨닫고 얻는게 아니라 오히려 불쾌하다.
아무리 국비로 진행하는 무료 부트캠프라지만 얘네도 나라에서 돈 받을거 아니야...
강의를 통해서 내가 다음에 진행할 부분이 어떤건지 확인하는 목차 정도로만 이용하는게 가장 좋을것같다.